{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm5sD9Qt69Aw"
      },
      "source": [
        "# Text Classification with From-Scratch Transformer\n",
        "\n",
        "This notebook implements:\n",
        "1. A complete transformer-style classifier from scratch (Part b)\n",
        "2. An efficient attention variant (Linear Attention) with comparisons (Part c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZr3ZRdz7WVq",
        "outputId": "ab9846d2-88a9-4170-b0e8-3941b37a9783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m839.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib torch scikit-learn gensim nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URxw2oY_8O8K",
        "outputId": "34413cc5-38fc-45b1-e183-1ff03eb53d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade numpy gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjmvTeqc8zAq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import time\n",
        "import math\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEbYMnbT7F9C"
      },
      "source": [
        "## Part B: From-Scratch Transformer Classifier\n",
        "\n",
        "### 1. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzvuQxuc7Cb0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('train.csv')  # Update with your path\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(df.head())\n",
        "\n",
        "# Preprocessing functions\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# Apply preprocessing\n",
        "df['processed_text'] = df['Text'].apply(preprocess_text)\n",
        "\n",
        "# Encode labels\n",
        "label_map = {label: idx for idx, label in enumerate(df['Category'].unique())}\n",
        "df['label'] = df['Category'].map(label_map)\n",
        "\n",
        "# Split data\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}\")\n",
        "print(f\"Number of classes: {len(label_map)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loqO1rh673RJ"
      },
      "outputs": [],
      "source": [
        "sentences = df['processed_text'].tolist()\n",
        "w2v_model = Word2Vec(sentences=sentences, vector_size=128, window=5, min_count=1, workers=4)\n",
        "w2v_model.train(sentences, total_examples=len(sentences), epochs=10)\n",
        "\n",
        "# Create embedding matrix\n",
        "vocab_size = len(w2v_model.wv)\n",
        "embedding_dim = w2v_model.vector_size\n",
        "embedding_matrix = np.zeros((vocab_size + 1, embedding_dim))  # +1 for padding token\n",
        "\n",
        "for i in range(len(w2v_model.wv)):\n",
        "    embedding_matrix[i] = w2v_model.wv[i]\n",
        "\n",
        "# Padding token is at index vocab_size\n",
        "embedding_matrix[vocab_size] = np.zeros(embedding_dim)\n",
        "\n",
        "# Token to index mapping\n",
        "word_to_idx = {word: idx for idx, word in enumerate(w2v_model.wv.index_to_key)}\n",
        "word_to_idx['<PAD>'] = vocab_size  # Add padding token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxLqLPMj8n1m"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, dataframe, word_to_idx, max_len=128):\n",
        "        self.data = dataframe\n",
        "        self.word_to_idx = word_to_idx\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data.iloc[idx]['processed_text']\n",
        "        label = self.data.iloc[idx]['label']\n",
        "\n",
        "        # Convert tokens to indices\n",
        "        indices = [self.word_to_idx.get(token, self.word_to_idx['<PAD>']) for token in text]\n",
        "\n",
        "        # Pad or truncate\n",
        "        if len(indices) < self.max_len:\n",
        "            indices = indices + [self.word_to_idx['<PAD>']] * (self.max_len - len(indices))\n",
        "        else:\n",
        "            indices = indices[:self.max_len]\n",
        "\n",
        "        return torch.LongTensor(indices), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "max_len = 128\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = TextDataset(train_df, word_to_idx, max_len)\n",
        "val_dataset = TextDataset(val_df, word_to_idx, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US-62qhH8ogF"
      },
      "source": [
        "### 2. Transformer Components Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7HHI53C8qYd"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Apgh2i-V8wpe"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_probs = F.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnEiKvBH8301"
      },
      "outputs": [],
      "source": [
        "# Feed Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=2048):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N43DDGG584Mx"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff=2048):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = x + self.dropout1(attn_output)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = x + self.dropout2(ffn_output)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1Q2JmrZ87G-"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, num_layers, num_heads, max_len):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim, padding_idx=vocab_size)\n",
        "\n",
        "        # Initialize with Word2Vec embeddings\n",
        "        self.embedding.weight.data[:-1] = torch.from_numpy(embedding_matrix[:-1])\n",
        "        self.embedding.weight.requires_grad = True  # Fine-tune embeddings\n",
        "\n",
        "        # Positional encoding\n",
        "        self.positional_encoding = PositionalEncoding(embedding_dim, max_len)\n",
        "\n",
        "        # Transformer layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(embedding_dim, num_heads)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, embedding_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(embedding_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding and positional encoding\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "        # Transformer layers\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Use the [CLS] token equivalent (mean pooling in our case)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Classification\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk3zs3Ah89-F"
      },
      "source": [
        "### 3. Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRPTzZc18_l5"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = len(label_map)\n",
        "num_layers = 3\n",
        "num_heads = 4\n",
        "\n",
        "model = TransformerClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    num_classes=num_classes,\n",
        "    num_layers=num_layers,\n",
        "    num_heads=num_heads,\n",
        "    max_len=max_len\n",
        ").to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "# %%\n",
        "# Training function\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        inputs, labels = batch\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1\n",
        "\n",
        "# Validation function\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1\n",
        "\n",
        "# %%\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_metrics = []\n",
        "val_metrics = []\n",
        "\n",
        "best_f1 = 0\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc, train_prec, train_rec, train_f1 = train_epoch(\n",
        "        model, train_loader, criterion, optimizer, device\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step(val_f1)\n",
        "\n",
        "    # Store metrics\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_metrics.append((train_acc, train_prec, train_rec, train_f1))\n",
        "    val_metrics.append((val_acc, val_prec, val_rec, val_f1))\n",
        "\n",
        "    # Save best model\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        best_model = model.state_dict()\n",
        "\n",
        "    # Print progress\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - {elapsed:.2f}s\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "    print(f\"Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model)\n",
        "\n",
        "# %%\n",
        "# Plot training curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "train_accs = [m[0] for m in train_metrics]\n",
        "val_accs = [m[0] for m in val_metrics]\n",
        "plt.plot(train_accs, label='Train Accuracy')\n",
        "plt.plot(val_accs, label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# Final evaluation\n",
        "val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate(model, val_loader, criterion, device)\n",
        "print(f\"Final Validation Metrics:\")\n",
        "print(f\"Loss: {val_loss:.4f}\")\n",
        "print(f\"Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Precision: {val_prec:.4f}\")\n",
        "print(f\"Recall: {val_rec:.4f}\")\n",
        "print(f\"F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "\n",
        "# Linear Attention Implementation\n",
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(LinearAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Feature map for linear attention\n",
        "        self.feature_map = nn.Sequential(\n",
        "            nn.Linear(self.d_k, self.d_k),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def elu_feature_map(self, x):\n",
        "        return F.elu(x) + 1\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        batch_size = Q.size(0)\n",
        "\n",
        "        # Project queries, keys, values\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Apply feature map\n",
        "        Q = self.elu_feature_map(Q)\n",
        "        K = self.elu_feature_map(K)\n",
        "\n",
        "        # Compute KV matrix first (more efficient for longer sequences)\n",
        "        KV = torch.einsum('bhnd,bhne->bhde', K, V)\n",
        "\n",
        "        # Compute numerator\n",
        "        Z = 1 / (torch.einsum('bhnd,bhd->bhn', Q, K.sum(dim=2)) + 1e-6)\n",
        "        V = torch.einsum('bhn,bhde,bhnd->bhne', Z, KV, Q)\n",
        "\n",
        "        # Combine heads\n",
        "        V = V.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        output = self.W_o(V)\n",
        "\n",
        "        return output\n",
        "\n",
        "# %%\n",
        "# Transformer Encoder Layer with Linear Attention\n",
        "class LinearTransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff=2048):\n",
        "        super(LinearTransformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = LinearAttention(d_model, num_heads)\n",
        "        self.ffn = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = x + self.dropout1(attn_output)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = x + self.dropout2(ffn_output)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# %%\n",
        "# Transformer Model with Linear Attention\n",
        "class LinearTransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, num_layers, num_heads, max_len):\n",
        "        super(LinearTransformerClassifier, self).__init__()\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim, padding_idx=vocab_size)\n",
        "        self.embedding.weight.data[:-1] = torch.from_numpy(embedding_matrix[:-1])\n",
        "        self.embedding.weight.requires_grad = True\n",
        "\n",
        "        # Positional encoding\n",
        "        self.positional_encoding = PositionalEncoding(embedding_dim, max_len)\n",
        "\n",
        "        # Transformer layers with linear attention\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            LinearTransformerEncoderLayer(embedding_dim, num_heads)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, embedding_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(embedding_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# %%\n",
        "# Initialize linear attention model\n",
        "linear_model = LinearTransformerClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    num_classes=num_classes,\n",
        "    num_layers=num_layers,\n",
        "    num_heads=num_heads,\n",
        "    max_len=max_len\n",
        ").to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "linear_criterion = nn.CrossEntropyLoss()\n",
        "linear_optimizer = optim.AdamW(linear_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "linear_scheduler = optim.lr_scheduler.ReduceLROnPlateau(linear_optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "# %%\n",
        "# Training loop for linear attention\n",
        "linear_train_losses = []\n",
        "linear_val_losses = []\n",
        "linear_train_metrics = []\n",
        "linear_val_metrics = []\n",
        "\n",
        "linear_best_f1 = 0\n",
        "linear_best_model = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc, train_prec, train_rec, train_f1 = train_epoch(\n",
        "        linear_model, train_loader, linear_criterion, linear_optimizer, device\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate(\n",
        "        linear_model, val_loader, linear_criterion, device\n",
        "    )\n",
        "\n",
        "    # Update scheduler\n",
        "    linear_scheduler.step(val_f1)\n",
        "\n",
        "    # Store metrics\n",
        "    linear_train_losses.append(train_loss)\n",
        "    linear_val_losses.append(val_loss)\n",
        "    linear_train_metrics.append((train_acc, train_prec, train_rec, train_f1))\n",
        "    linear_val_metrics.append((val_acc, val_prec, val_rec, val_f1))\n",
        "\n",
        "    # Save best model\n",
        "    if val_f1 > linear_best_f1:\n",
        "        linear_best_f1 = val_f1\n",
        "        linear_best_model = linear_model.state_dict()\n",
        "\n",
        "    # Print progress\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - {elapsed:.2f}s\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "    print(f\"Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# Load best model\n",
        "linear_model.load_state_dict(linear_best_model)\n",
        "\n",
        "# %%\n",
        "# Compare standard and linear attention\n",
        "def compare_models(standard_model, linear_model, dataloader, device):\n",
        "    # Standard attention\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, _ = batch\n",
        "            inputs = inputs.to(device)\n",
        "            _ = standard_model(inputs)\n",
        "    standard_time = time.time() - start_time\n",
        "\n",
        "    # Linear attention\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, _ = batch\n",
        "            inputs = inputs.to(device)\n",
        "            _ = linear_model(inputs)\n",
        "    linear_time = time.time() - start_time\n",
        "\n",
        "    # Memory usage\n",
        "    standard_mem = torch.cuda.max_memory_allocated(device) if torch.cuda.is_available() else 0\n",
        "    torch.cuda.reset_peak_memory_stats(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, _ = batch\n",
        "            inputs = inputs.to(device)\n",
        "            _ = linear_model(inputs)\n",
        "    linear_mem = torch.cuda.max_memory_allocated(device) if torch.cuda.is_available() else 0\n",
        "\n",
        "    return {\n",
        "        'standard_time': standard_time,\n",
        "        'linear_time': linear_time,\n",
        "        'standard_mem': standard_mem,\n",
        "        'linear_mem': linear_mem\n",
        "    }\n",
        "\n",
        "# Performance comparison\n",
        "comparison = compare_models(model, linear_model, val_loader, device)\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(f\"Standard Attention Time: {comparison['standard_time']:.4f}s\")\n",
        "print(f\"Linear Attention Time: {comparison['linear_time']:.4f}s\")\n",
        "print(f\"Speedup: {comparison['standard_time'] / comparison['linear_time']:.2f}x\")\n",
        "print(f\"Standard Attention Memory: {comparison['standard_mem'] / 1024**2:.2f}MB\")\n",
        "print(f\"Linear Attention Memory: {comparison['linear_mem'] / 1024**2:.2f}MB\")\n",
        "\n",
        "# %%\n",
        "# Final evaluation of linear attention model\n",
        "val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate(linear_model, val_loader, linear_criterion, device)\n",
        "print(f\"\\nLinear Attention Validation Metrics:\")\n",
        "print(f\"Loss: {val_loss:.4f}\")\n",
        "print(f\"Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Precision: {val_prec:.4f}\")\n",
        "print(f\"Recall: {val_rec:.4f}\")\n",
        "print(f\"F1 Score: {val_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6L0o4m79QCy"
      },
      "source": [
        "\"\"\"\n",
        "## Analysis of Linear Attention\n",
        "\n",
        "### Mathematical Basis for Efficiency Gains\n",
        "\n",
        "Standard attention computes:\n",
        "\\[ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\]\n",
        "\n",
        "This has O(N^2) complexity due to the QK^T matrix multiplication.\n",
        "\n",
        "Linear attention reformulates this as:\n",
        "\\[ \\text{Attention}(Q, K, V) = \\phi(Q)(\\phi(K)^T V \\]\n",
        "where φ is a feature map (we used ELU(x)+1).\n",
        "\n",
        "By associativity, we can compute (φ(K)^T V) first, reducing complexity to O(N).\n",
        "\n",
        "### Theoretical Advantages and Limitations\n",
        "\n",
        "Advantages:\n",
        "1. Linear complexity with sequence length (O(N) vs O(N^2))\n",
        "2. Better memory efficiency\n",
        "3. Can handle much longer sequences\n",
        "\n",
        "Limitations:\n",
        "1. Approximation may lose some expressive power\n",
        "2. Feature map choice is crucial for performance\n",
        "3. May require more layers to achieve similar performance\n",
        "\n",
        "### Implementation Complexity\n",
        "\n",
        "The implementation adds:\n",
        "1. Feature map application (simple feed-forward)\n",
        "2. Changed computation order (KV product first)\n",
        "3. Normalization term (Z)\n",
        "\n",
        "Overall complexity increase is modest (~20% more code) for significant speed gains.\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
